{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75ef551",
   "metadata": {},
   "source": [
    "# Text Analytics Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7937549",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86eb82",
   "metadata": {},
   "source": [
    "# Task 1: Sentiment Classification\n",
    "\n",
    "## Amazon Reviews\n",
    "\n",
    "This dataset contains Amazon reviews in different languages along with their star ratings from 1 to 5. You can choose which language to work with. The code below passes the argument 'en' to load English reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56eab56",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (./data_cache\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2fe811de0f4a70a96e1e119fa796d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with two splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 200000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"amazon_reviews_multi\", \n",
    "    'en', # Select language of the dataset\n",
    "    cache_dir='./data_cache'\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with two splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba5e04",
   "metadata": {},
   "source": [
    "The dataset already contains a test split, which we can hold out until we have tuned our method(s), and a validation split (also called 'development' set or 'devset'), as well as the training split. \n",
    "\n",
    "The validation set can be used to compute performance of your model when tuning hyperparameters,  optimising combinations of features, or looking at the errors your model makes before improving it. This allows you to hold out the test set (i.e., not to look at examples from the test set while developing the model) to give a fair evaluation of the model and how well it generalises to new examples. This avoids tuning the model to specific examples in the test set.\n",
    "\n",
    "There are several approaches to validation: instead of using the presupplised validation set, you could use [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html). \n",
    "\n",
    "The text below loads each of the splits into a set of documents and a set of corresponding review score labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c774eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training document: Arrived broken. Manufacturer defect. Two of the legs of the base were not completely formed, so there was no way to insert the casters. I unpackaged the entire chair and hardware before noticing this. So, I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review of part of a chair I never got to sit in. I will go so far as to include a picture of what their injection molding and quality assurance process missed though. I will be hesitant to buy again. It makes me wonder if there aren't missing structures and supports that don't impede the assembly process.\n",
      "Corresponding review score: 1\n",
      "Number of training instances: 200000\n",
      "Number of validation instances: 5000\n",
      "Number of test instances: 5000\n"
     ]
    }
   ],
   "source": [
    "train_documents = dataset[\"train\"]['review_body']\n",
    "print(f'Example training document: {train_documents[0]}')\n",
    "train_labels = dataset[\"train\"]['stars']\n",
    "print(f'Corresponding review score: {train_labels[0]}')\n",
    "print(f'Number of training instances: {len(train_documents)}')\n",
    "\n",
    "val_documents = dataset[\"validation\"]['review_body']\n",
    "print(f'Number of validation instances: {len(val_documents)}')\n",
    "val_labels = dataset[\"validation\"]['stars']\n",
    "\n",
    "test_documents = dataset[\"test\"]['review_body']\n",
    "print(f'Number of test instances: {len(test_documents)}')\n",
    "test_labels = dataset[\"test\"]['stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0dbde",
   "metadata": {},
   "source": [
    "The star ratings are our classes in this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0573c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5aed5",
   "metadata": {},
   "source": [
    "The training set is very large, so you may wish to work with a subset of the training data by using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a5b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_documents, unused_documents, train_labels, unused_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.9, \n",
    "    stratify=train_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b138052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the train dataset? \n",
      "\n",
      "20000\n",
      "\n",
      "What does one instance look like? \n",
      "\n",
      "Love the fragrance, but the bottle is shape makes it difficult to dispense. Shipped and described as advertised.\n"
     ]
    }
   ],
   "source": [
    "# label 0 = negative, 1 = neutral, 2 = positive\n",
    "print(f'How many instances in the train dataset? \\n\\n{len(train_documents)}')\n",
    "print('')\n",
    "print(f'What does one instance look like? \\n\\n{train_documents[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3912457",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "This step is to tokenise the text of each document and convert it to a bag of words, ready for input to a classifier. To extract a bag of words, we can use the CountVectorizer class. This class outputs the bag of words as a feature vector, where the length of the vector is equal to the size of the vocabulary, and the values are the counts of each words in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658cedce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Download\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# CountVectorizer can do its own tokenization, but for consistency we want to\n",
    "# carry on using WordNetTokenizer. We write a small wrapper class to enable this:\n",
    "class Tokenizer(object):\n",
    "    def __call__(self, docs):\n",
    "        return word_tokenize(docs)\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=Tokenizer())  # construct the vectorizer\n",
    "\n",
    "vectorizer.fit(train_documents)  # Learn the vocabulary\n",
    "X_train = vectorizer.transform(train_documents)  # extract training set bags of words\n",
    "X_val = vectorizer.transform(val_documents)  # extract validation set bags of words\n",
    "X_test = vectorizer.transform(test_documents)  # extract test set bags of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c0a14",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "For our bag of words data, we use the [MultinomialNB class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc868a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc65deb",
   "metadata": {},
   "source": [
    "Now we have a trained model, we would like to evaluate its performance on some test data.\n",
    "\n",
    "Predict the labels for the validation set. Use X_val as the inputs to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141f9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758d22a",
   "metadata": {},
   "source": [
    "We can compute standard metrics for classifier performance using scikit-learn's metrics libary. A useful function for multi-class classification (when there are more than two classes) is the classification report function.\n",
    "\n",
    "Compute accuracy, precision, recall and F1 scores on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0c6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4836\n",
      "Precision (macro average) = 0.48149950136807035\n",
      "Recall (macro average) = 0.48360000000000003\n",
      "F1 score (macro average) = 0.48176614091588926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.62      0.59      1000\n",
      "           2       0.38      0.38      0.38      1000\n",
      "           3       0.37      0.39      0.38      1000\n",
      "           4       0.43      0.37      0.40      1000\n",
      "           5       0.66      0.67      0.66      1000\n",
      "\n",
      "    accuracy                           0.48      5000\n",
      "   macro avg       0.48      0.48      0.48      5000\n",
      "weighted avg       0.48      0.48      0.48      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "acc = accuracy_score(val_labels, val_pred)\n",
    "print(f'Accuracy = {acc}')\n",
    "\n",
    "prec = precision_score(val_labels, val_pred, average='macro')\n",
    "print(f'Precision (macro average) = {prec}')\n",
    "\n",
    "rec = recall_score(val_labels, val_pred, average='macro')\n",
    "print(f'Recall (macro average) = {rec}')\n",
    "\n",
    "f1 = f1_score(val_labels, val_pred, average='macro')\n",
    "print(f'F1 score (macro average) = {f1}')\n",
    "\n",
    "print(classification_report(val_labels, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c1800",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "Lemmatization is useful for reducing the size of the vocabulary.\n",
    "\n",
    "To apply lemmatization, we have to go back to the CountVectorizer and define a new tokenizer that will carry out the extra step of lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1e6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Download\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, tweets):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(tweets)]\n",
    "    \n",
    "vectorizer2 = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "\n",
    "vectorizer2.fit(train_documents)\n",
    "Xtrain = vectorizer2.transform(train_documents)\n",
    "Xval = vectorizer2.transform(val_documents)\n",
    "Xtest = vectorizer2.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a39560e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just as described, works fine.Its not as good as my old shark, maybe the smaller cleaning surface is the problem. I had very high expectations for this steamer. Light weight, good cleaning capabilities, leaves surfaces fresh and hygienic, lots of accessories. Leaks water if you stay still for more than a few seconds, even in low settings, so you need to move fast.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae69e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(Xtrain, train_labels)\n",
    "valpred = clf.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940ca7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4726\n",
      "Precision (macro average) = 0.4701215045659038\n",
      "Recall (macro average) = 0.4726\n",
      "F1 score (macro average) = 0.47057475617585565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.60      0.58      1000\n",
      "           2       0.36      0.36      0.36      1000\n",
      "           3       0.35      0.37      0.36      1000\n",
      "           4       0.43      0.36      0.39      1000\n",
      "           5       0.65      0.67      0.66      1000\n",
      "\n",
      "    accuracy                           0.47      5000\n",
      "   macro avg       0.47      0.47      0.47      5000\n",
      "weighted avg       0.47      0.47      0.47      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(val_labels, valpred)\n",
    "print(f'Accuracy = {acc}')\n",
    "\n",
    "prec = precision_score(val_labels, valpred, average='macro')\n",
    "print(f'Precision (macro average) = {prec}')\n",
    "\n",
    "rec = recall_score(val_labels, valpred, average='macro')\n",
    "print(f'Recall (macro average) = {rec}')\n",
    "\n",
    "f1 = f1_score(val_labels, valpred, average='macro')\n",
    "print(f'F1 score (macro average) = {f1}')\n",
    "\n",
    "print(classification_report(val_labels, valpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8453732",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "\n",
    "The bag of words is a very simple representation of the tweets that does not capture enough information to make accurate sentiment classifications. Another way to improve it could be to use bigrams instead of single words as our features. Bigrams are pairs of words that occur one after another in the text. Bigrams are a kind of 'n-gram', where 'n=2'.\n",
    "\n",
    "To extract bigrams, we again modify our CountVectorizer. This class has a parameter `ngram_range`, which determines the range of sizes of n-grams the vectorizer will include. If we set `ngram_range=(1,1)` we have our standard bag of words. If we set it to `ngram_range=(2,2)`, we use bigrams instead. Choosing If we set `ngram_range=(1,2)` will use both single tokens (unigrams) and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2afcfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Download\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer3 = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(2,2))\n",
    "\n",
    "vectorizer3.fit(train_documents)\n",
    "Xtrain = vectorizer3.transform(train_documents)\n",
    "Xval = vectorizer3.transform(val_documents)\n",
    "Xtest = vectorizer3.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc7ed37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(Xtrain, train_labels)\n",
    "valpred = clf.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efac0b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4844\n",
      "Precision (macro average) = 0.496537492579941\n",
      "Recall (macro average) = 0.48439999999999994\n",
      "F1 score (macro average) = 0.48905701530690954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.58      0.59      1000\n",
      "           2       0.36      0.42      0.39      1000\n",
      "           3       0.36      0.39      0.37      1000\n",
      "           4       0.45      0.41      0.43      1000\n",
      "           5       0.71      0.61      0.66      1000\n",
      "\n",
      "    accuracy                           0.48      5000\n",
      "   macro avg       0.50      0.48      0.49      5000\n",
      "weighted avg       0.50      0.48      0.49      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(val_labels, valpred)\n",
    "print(f'Accuracy = {acc}')\n",
    "\n",
    "prec = precision_score(val_labels, valpred, average='macro')\n",
    "print(f'Precision (macro average) = {prec}')\n",
    "\n",
    "rec = recall_score(val_labels, valpred, average='macro')\n",
    "print(f'Recall (macro average) = {rec}')\n",
    "\n",
    "f1 = f1_score(val_labels, valpred, average='macro')\n",
    "print(f'F1 score (macro average) = {f1}')\n",
    "\n",
    "print(classification_report(val_labels, valpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5e4cc",
   "metadata": {},
   "source": [
    "## Test the model on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98144d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4822\n",
      "Precision (macro average) = 0.49324143420067734\n",
      "Recall (macro average) = 0.4821999999999999\n",
      "F1 score (macro average) = 0.4859905380884406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.61      0.59      1000\n",
      "           2       0.37      0.42      0.40      1000\n",
      "           3       0.36      0.38      0.37      1000\n",
      "           4       0.45      0.42      0.44      1000\n",
      "           5       0.70      0.58      0.63      1000\n",
      "\n",
      "    accuracy                           0.48      5000\n",
      "   macro avg       0.49      0.48      0.49      5000\n",
      "weighted avg       0.49      0.48      0.49      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ypred = clf.predict(Xtest)\n",
    "\n",
    "acc = accuracy_score(test_labels, Ypred)\n",
    "print(f'Accuracy = {acc}')\n",
    "\n",
    "prec = precision_score(test_labels, Ypred, average='macro')\n",
    "print(f'Precision (macro average) = {prec}')\n",
    "\n",
    "rec = recall_score(test_labels, Ypred, average='macro')\n",
    "print(f'Recall (macro average) = {rec}')\n",
    "\n",
    "f1 = f1_score(test_labels, Ypred, average='macro')\n",
    "print(f'F1 score (macro average) = {f1}')\n",
    "\n",
    "print(classification_report(test_labels, Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f36e4",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffcd10",
   "metadata": {},
   "source": [
    "### data preprocessing\n",
    "\n",
    "To apply topic modelling, we need to first preprocess the data. We will carry out the following steps using the same approach as previous labs:\n",
    "* Tokenise the posts using NLTK's word_tokenize() function\n",
    "* Remove non-word tokens and tokens with length less than 3 (likely to be numbers and punctuation that are not related to specific topics) and longer than 15 (probably URLs, codes, andbadly formatted tokens rather than proper words)\n",
    "* Convert the tokens to lower case\n",
    "* Remove stopwords: we have not used this step before; it removes tokens such as 'the' and 'a' that appear in a list of very common words, because these words do not tell us much about topics\n",
    "* Lemmatize the tokens using WordNetLemmatizer to convert verbs to their root forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fd20ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS # find stopwords\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    # Tokenize, remove very short and very long words, convert to lower case, remove words containing non-letter characters\n",
    "    for token in simple_preprocess(text) : \n",
    "        if token not in STOPWORDS:\n",
    "            result.append(WordNetLemmatizer().lemmatize(token, 'v'))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84d2b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of preprocessed documents\n",
    "processed = []\n",
    "for i, doc in enumerate(train_documents):\n",
    "    if train_labels[i] == 1 or train_labels[i] == 5:\n",
    "        processed.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ead290b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(processed) # construct word<->id mappings - it does it in alphabetical order\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c071915",
   "metadata": {},
   "source": [
    "We are going to try 20 topics in the document corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9b87759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "lda_model =  LdaModel(bow_corpus, \n",
    "                      num_topics=20, \n",
    "                      id2word=dictionary,                                    \n",
    "                      passes=10,\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f0c91a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.054*\"love\" + 0.043*\"picture\" + 0.031*\"gift\" + 0.022*\"son\" + 0.021*\"order\" + 0.021*\"daughter\" + 0.019*\"buy\" + 0.019*\"beautiful\" + 0.018*\"year\" + 0.017*\"get\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.030*\"pair\" + 0.027*\"cheap\" + 0.022*\"shoe\" + 0.016*\"ear\" + 0.015*\"hole\" + 0.015*\"smaller\" + 0.012*\"feet\" + 0.012*\"better\" + 0.012*\"plastic\" + 0.012*\"part\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.027*\"love\" + 0.024*\"purchase\" + 0.024*\"use\" + 0.022*\"happy\" + 0.021*\"color\" + 0.021*\"product\" + 0.021*\"hair\" + 0.020*\"wash\" + 0.018*\"like\" + 0.015*\"smell\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.043*\"charge\" + 0.032*\"buy\" + 0.031*\"time\" + 0.026*\"battery\" + 0.025*\"work\" + 0.022*\"turn\" + 0.022*\"days\" + 0.022*\"months\" + 0.017*\"return\" + 0.016*\"start\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.066*\"good\" + 0.050*\"case\" + 0.046*\"price\" + 0.046*\"great\" + 0.045*\"quality\" + 0.039*\"phone\" + 0.025*\"screen\" + 0.020*\"product\" + 0.020*\"fit\" + 0.019*\"look\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.042*\"sound\" + 0.028*\"quality\" + 0.020*\"play\" + 0.017*\"phone\" + 0.017*\"great\" + 0.016*\"poor\" + 0.015*\"game\" + 0.015*\"work\" + 0.014*\"like\" + 0.012*\"headphones\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.049*\"product\" + 0.041*\"arrive\" + 0.034*\"break\" + 0.025*\"ship\" + 0.021*\"company\" + 0.021*\"amazon\" + 0.021*\"service\" + 0.021*\"say\" + 0.020*\"come\" + 0.019*\"fast\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.032*\"cable\" + 0.027*\"work\" + 0.019*\"light\" + 0.019*\"power\" + 0.015*\"car\" + 0.013*\"week\" + 0.013*\"instal\" + 0.013*\"band\" + 0.012*\"get\" + 0.011*\"arm\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.080*\"easy\" + 0.036*\"use\" + 0.028*\"clean\" + 0.024*\"cover\" + 0.022*\"install\" + 0.020*\"great\" + 0.017*\"glass\" + 0.016*\"work\" + 0.016*\"tool\" + 0.015*\"job\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.035*\"use\" + 0.019*\"work\" + 0.014*\"time\" + 0.014*\"product\" + 0.012*\"come\" + 0.012*\"need\" + 0.011*\"best\" + 0.011*\"instructions\" + 0.010*\"usb\" + 0.010*\"easy\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.064*\"money\" + 0.041*\"waste\" + 0.035*\"product\" + 0.030*\"buy\" + 0.026*\"time\" + 0.023*\"star\" + 0.017*\"like\" + 0.016*\"review\" + 0.015*\"try\" + 0.014*\"taste\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.024*\"day\" + 0.024*\"ve\" + 0.022*\"like\" + 0.018*\"help\" + 0.017*\"try\" + 0.016*\"water\" + 0.014*\"wear\" + 0.014*\"take\" + 0.014*\"get\" + 0.013*\"hot\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.064*\"order\" + 0.058*\"receive\" + 0.055*\"item\" + 0.054*\"return\" + 0.044*\"send\" + 0.036*\"seller\" + 0.028*\"amazon\" + 0.021*\"get\" + 0.020*\"box\" + 0.020*\"refund\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.059*\"fit\" + 0.042*\"perfect\" + 0.031*\"great\" + 0.028*\"love\" + 0.026*\"bag\" + 0.024*\"look\" + 0.022*\"size\" + 0.018*\"cute\" + 0.018*\"super\" + 0.018*\"small\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.038*\"light\" + 0.022*\"dry\" + 0.020*\"bottle\" + 0.015*\"feel\" + 0.015*\"like\" + 0.014*\"bright\" + 0.014*\"great\" + 0.013*\"oil\" + 0.012*\"room\" + 0.011*\"nice\"\n",
      "\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.042*\"like\" + 0.020*\"look\" + 0.020*\"watch\" + 0.015*\"baby\" + 0.014*\"handle\" + 0.013*\"buy\" + 0.013*\"bed\" + 0.012*\"problem\" + 0.011*\"sleep\" + 0.011*\"stand\"\n",
      "\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.056*\"book\" + 0.036*\"read\" + 0.034*\"size\" + 0.031*\"love\" + 0.015*\"order\" + 0.014*\"wear\" + 0.014*\"comfortable\" + 0.013*\"like\" + 0.013*\"great\" + 0.012*\"enjoy\"\n",
      "\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.037*\"recommend\" + 0.032*\"exactly\" + 0.023*\"highly\" + 0.021*\"quality\" + 0.021*\"love\" + 0.018*\"describe\" + 0.015*\"fall\" + 0.015*\"look\" + 0.014*\"buy\" + 0.014*\"product\"\n",
      "\n",
      "\n",
      "Topic: 18 \n",
      "Words: 0.247*\"work\" + 0.051*\"great\" + 0.050*\"stop\" + 0.020*\"product\" + 0.020*\"months\" + 0.015*\"go\" + 0.014*\"month\" + 0.014*\"buy\" + 0.010*\"light\" + 0.010*\"plug\"\n",
      "\n",
      "\n",
      "Topic: 19 \n",
      "Words: 0.024*\"open\" + 0.019*\"dog\" + 0.017*\"try\" + 0.016*\"miss\" + 0.015*\"disappoint\" + 0.015*\"stick\" + 0.015*\"leak\" + 0.014*\"break\" + 0.013*\"review\" + 0.012*\"box\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For each topic, we will explore the words occuring in that topic and its relative weight\n",
    "'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b2de2",
   "metadata": {},
   "source": [
    "## Hierarchical Dirichlet Process (HDP)\n",
    "\n",
    "Instead of passing in a fixed number of topics, HDP will try to learn a good number of topics to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7259cdbb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.008*work + 0.006*like + 0.006*great + 0.006*product + 0.006*buy + 0.005*time + 0.005*use + 0.005*good + 0.004*look + 0.004*love\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.006*like + 0.005*work + 0.005*buy + 0.004*product + 0.004*use + 0.004*love + 0.004*great + 0.004*look + 0.004*time + 0.003*good\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.002*product + 0.002*work + 0.002*like + 0.002*buy + 0.002*great + 0.002*come + 0.002*screen + 0.001*look + 0.001*love + 0.001*read\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.003*work + 0.002*buy + 0.002*time + 0.002*like + 0.002*product + 0.002*great + 0.002*use + 0.002*get + 0.002*love + 0.001*bag\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.003*like + 0.003*work + 0.002*time + 0.002*use + 0.002*buy + 0.002*good + 0.002*great + 0.002*easy + 0.002*product + 0.002*get\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.003*work + 0.002*product + 0.002*like + 0.002*great + 0.002*love + 0.002*buy + 0.002*use + 0.002*order + 0.001*fit + 0.001*need\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.002*work + 0.001*product + 0.001*like + 0.001*great + 0.001*time + 0.001*nordstrom + 0.001*buy + 0.001*need + 0.001*love + 0.001*ford\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.002*work + 0.001*product + 0.001*buy + 0.001*great + 0.001*good + 0.001*love + 0.001*like + 0.001*think + 0.001*seller + 0.001*easy\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.001*great + 0.001*product + 0.001*use + 0.001*work + 0.001*like + 0.001*look + 0.001*good + 0.001*vinyl + 0.001*buy + 0.001*box\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.002*good + 0.001*use + 0.001*work + 0.001*product + 0.001*like + 0.001*buy + 0.001*love + 0.001*look + 0.001*fund + 0.001*great\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.002*work + 0.002*buy + 0.001*love + 0.001*like + 0.001*great + 0.001*use + 0.001*product + 0.001*specifically + 0.001*spong + 0.001*easy\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.002*work + 0.002*try + 0.001*seat + 0.001*time + 0.001*cleaner + 0.001*instal + 0.001*use + 0.001*cr + 0.001*product + 0.001*entertainment\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.002*product + 0.002*like + 0.001*work + 0.001*buy + 0.001*try + 0.001*use + 0.001*wipe + 0.001*time + 0.001*halogen + 0.001*great\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.001*like + 0.001*great + 0.001*use + 0.001*work + 0.001*hurrah + 0.001*tingly + 0.001*product + 0.001*porous + 0.001*brass + 0.001*buy\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.001*great + 0.001*work + 0.001*product + 0.001*use + 0.001*porch + 0.001*like + 0.001*pizza + 0.001*sprout + 0.001*shatter + 0.001*blow\n",
      "\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.002*work + 0.001*product + 0.001*time + 0.001*great + 0.001*like + 0.001*rewind + 0.001*softballs + 0.001*coffee + 0.001*charge + 0.001*nozzles\n",
      "\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.001*work + 0.001*buy + 0.001*like + 0.001*use + 0.001*pi + 0.001*laptops + 0.001*return + 0.001*dept + 0.001*great + 0.001*lubricant\n",
      "\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.002*work + 0.001*great + 0.001*product + 0.001*book + 0.001*cleanup + 0.001*glance + 0.001*staple + 0.001*buy + 0.001*like + 0.001*ace\n",
      "\n",
      "\n",
      "Topic: 18 \n",
      "Words: 0.002*work + 0.002*move + 0.002*great + 0.001*love + 0.001*like + 0.001*need + 0.001*product + 0.001*cruel + 0.001*use + 0.001*buy\n",
      "\n",
      "\n",
      "Topic: 19 \n",
      "Words: 0.001*product + 0.001*headband + 0.001*time + 0.001*work + 0.001*run + 0.001*buy + 0.001*like + 0.001*disposable + 0.001*exersaucer + 0.001*lotion\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import HdpModel\n",
    "\n",
    "hdp_model = HdpModel(bow_corpus, \n",
    "                     dictionary,\n",
    "                     alpha=0.01,\n",
    "                     gamma=0.01)\n",
    "\n",
    "# print the word-topic distributions for \n",
    "for idx, topic in hdp_model.print_topics(20):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16624b",
   "metadata": {},
   "source": [
    "The previous cell shows the first 20 topics. HDP learns the number of topics that are needed to model the dataset. It produces a global distribution over the topics. Topics with very low probability can be considered inactive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25342e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_global_topic_weights(hdp_model):\n",
    "    global_topic_weights = hdp_model.m_varphi_ss / np.sum(hdp_model.m_varphi_ss)\n",
    "\n",
    "    plt.bar(np.arange(len(global_topic_weights)), global_topic_weights)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Topic ID')\n",
    "    \n",
    "plot_global_topic_weights(hdp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42104d61",
   "metadata": {},
   "source": [
    "# Task 2: Named Entity Recognition\n",
    "\n",
    "## Bio Creative V\n",
    "\n",
    "This dataset contains sentences extracted from scientific articles on PubMed. The sentences are annotated with two types of entities, chemicals and diseases. Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6f3b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset bc5_cdr (./data_cache\\tner___bc5_cdr\\bc5cdr\\1.0.0\\66ea1a8c1cb0adcf8751ab7993f5d31717f21c2a9b89e21506fe959d904a7bf6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317a29f945db4db5a2f2f6402aebc87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with 3 splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5228\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5330\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 5865\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bc5cdr\", \n",
    "    cache_dir='./data_cache'\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with {len(dataset)} splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277de11",
   "metadata": {},
   "source": [
    "The data is also split into train, validation and test. It may be convenient to reformat these splits into lists of tokens and lists of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f915017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_ner = [item['tokens'] for item in dataset['train']]\n",
    "train_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['train']]\n",
    "\n",
    "val_sentences_ner = [item['tokens'] for item in dataset['validation']]\n",
    "val_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['validation']]\n",
    "\n",
    "test_sentences_ner = [item['tokens'] for item in dataset['test']]\n",
    "test_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10bf358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 5228\n",
      "Number of validation instances: 5330\n",
      "Number of test instances: 5865\n",
      "Example training sentence (already tokenised): ['Naloxone', 'reverses', 'the', 'antihypertensive', 'effect', 'of', 'clonidine', '.']\n",
      "...corresponding tags for the same example: ['1', '0', '0', '0', '0', '0', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training instances: {len(train_sentences_ner)}')\n",
    "print(f'Number of validation instances: {len(val_sentences_ner)}')\n",
    "print(f'Number of test instances: {len(test_sentences_ner)}')\n",
    "\n",
    "print(f'Example training sentence (already tokenised): {train_sentences_ner[0]}')\n",
    "print(f'...corresponding tags for the same example: {train_labels_ner[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48f691",
   "metadata": {},
   "source": [
    "These are the tags used to annotate the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b587c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-Chemical', 2: 'B-Disease', 3: 'I-Disease', 4: 'I-Chemical'}\n"
     ]
    }
   ],
   "source": [
    "id2label = {\n",
    "    \"O\": 0,\n",
    "    \"B-Chemical\": 1,\n",
    "    \"B-Disease\": 2,\n",
    "    \"I-Disease\": 3,\n",
    "    \"I-Chemical\": 4\n",
    "}\n",
    "\n",
    "label2id = {v:k for k, v in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0674b",
   "metadata": {},
   "source": [
    "Put the NER data in the right format for NLTK's CRFTagger class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e342512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(d, value):\n",
    "    res = []\n",
    "    for val in value:\n",
    "        for k, v in d.items():\n",
    "            if v == val:\n",
    "                res.append(k)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f9c4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [list(zip(train_sentences_ner[i], get_keys(id2label, [int(tok) for tok in train_labels_ner[i]]))) for i in range(len(train_sentences_ner))][:-1]\n",
    "val_dataset = [list(zip(val_sentences_ner[i], get_keys(id2label, [int(tok) for tok in val_labels_ner[i]]))) for i in range(len(val_sentences_ner))][:-1]\n",
    "test_dataset = [list(zip(test_sentences_ner[i], get_keys(id2label, [int(tok) for tok in test_labels_ner[i]]))) for i in range(len(test_sentences_ner))][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc782b",
   "metadata": {},
   "source": [
    "Train a CRF tagger on our training set. The method you need to use from NLTK is the [train method of the conditional random field (CRF)](https://www.nltk.org/_modules/nltk/tag/crf.html). You need to call the constructor with default arguments, then the train() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c852df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Train a CRF NER tagger\n",
    "def train_CRF_NER_tagger(train_set):\n",
    "    crf = nltk.tag.CRFTagger()\n",
    "    crf.train(train_set, 'model.crf.tagger')\n",
    "    return crf\n",
    "\n",
    "tagger = train_CRF_NER_tagger(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30d452",
   "metadata": {},
   "source": [
    "Get some predictions from the tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a0fe32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags_val = tagger.tag_sents(val_sentences_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6a67b",
   "metadata": {},
   "source": [
    "Let's see how well the tagger is performing. In NER, we evaluate performance by finding correctly matched entities, rather than correctly tagged tokens. Only an exact entity match counts as correct. Therefore, we need to compute precision, recall and F1 score by computing true positives, false positives and false negatives by looking for the predicted entity spans and the gold-labelled entity spans in the test set.\n",
    "\n",
    "The code below contains a function that extract a list of spans from the tagged sentences. The next function calls extract_spans() and computes the precision, recall and f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0b6ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spans(tagged_sents):\n",
    "    \"\"\"\n",
    "    Extract a list of tagged spans for each named entity type, \n",
    "    where each span is represented by a tuple containing the \n",
    "    start token and end token indexes.\n",
    "    \n",
    "    returns: a dictionary containing a list of spans for each entity type.\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "        \n",
    "    for sidx, sent in enumerate(tagged_sents):\n",
    "        start = -1\n",
    "        entity_type = None\n",
    "        for i, (tok, lab) in enumerate(sent):\n",
    "            if 'B-' in lab:\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                entity_type = lab[2:]\n",
    "            elif 'I-' in lab:\n",
    "                end = i + 1\n",
    "            elif lab == 'O' and start >= 0:\n",
    "                \n",
    "                if entity_type not in spans:\n",
    "                    spans[entity_type] = []\n",
    "                \n",
    "                spans[entity_type].append((start, end, sidx))\n",
    "                start = -1\n",
    "        # Sometimes an I-token is the last token in the sentence, so we still have to add the span to the list\n",
    "        if start >= 0:    \n",
    "            if entity_type not in spans:\n",
    "                spans[entity_type] = []\n",
    "                \n",
    "            spans[entity_type].append((start, end, sidx))    \n",
    "            \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0e8fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_span_level_f1(test_sents, test_sents_with_pred):\n",
    "    # get a list of spans from the test set labels\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "\n",
    "    # get a list of spans predicted by our tagger\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "    \n",
    "    # compute the metrics for each class:\n",
    "    f1_per_class = []\n",
    "    \n",
    "    ne_types = gold_spans.keys()  # get the list of named entity types (not the tags)\n",
    "    \n",
    "    for ne_type in ne_types:\n",
    "        # compute the confusion matrix\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        \n",
    "        for span in pred_spans[ne_type]:\n",
    "            if span in gold_spans[ne_type]:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "                \n",
    "        false_neg = 0\n",
    "        for span in gold_spans[ne_type]:\n",
    "            if span not in pred_spans[ne_type]:\n",
    "                false_neg += 1\n",
    "                \n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / float(true_pos + false_pos)\n",
    "            \n",
    "        if true_pos + false_neg == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = true_pos / float(true_pos + false_neg)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "        f1_per_class.append(f1)\n",
    "        print(f'F1 score for class {ne_type} = {f1}')\n",
    "        \n",
    "    print(f'Macro-average f1 score = {np.mean(f1_per_class)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb48ca",
   "metadata": {},
   "source": [
    "Run the cal_span_level_F1() function below to compute span-level F1 scores for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d143e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Disease = 0.65403103969235\n",
      "F1 score for class Chemical = 0.8277834525025537\n",
      "Macro-average f1 score = 0.7409072460974518\n"
     ]
    }
   ],
   "source": [
    "cal_span_level_f1(val_dataset, predicted_tags_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71ff0b",
   "metadata": {},
   "source": [
    "## Test the model on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ad00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.815220700152207\n",
      "F1 score for class Disease = 0.649018833135783\n",
      "Macro-average f1 score = 0.732119766643995\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = tagger.tag_sents(test_sentences_ner)\n",
    "cal_span_level_f1(test_dataset, predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45040b06",
   "metadata": {},
   "source": [
    "We can try to help the CRF tagger by adding some more features. Part-of-speech tags often provide useful information for identifying entites. The code below defines a modified CRFTagger class that overwrites the `_get_features()` method, which extracts the features from the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a69b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata\n",
    "\n",
    "class CustomCRFTagger(nltk.tag.CRFTagger):\n",
    "    _current_tokens = None\n",
    "    \n",
    "    def _get_features(self, tokens, idx):\n",
    "            \"\"\"\n",
    "            Extract basic features about this word including\n",
    "                - Current word\n",
    "                - is it capitalized?\n",
    "                - Does it have punctuation?\n",
    "                - Does it have a number?\n",
    "                - Suffixes up to length 3\n",
    "\n",
    "            Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "            :return: a list which contains the features\n",
    "            :rtype: list(str)\n",
    "            \"\"\"\n",
    "            token = tokens[idx]\n",
    "\n",
    "            feature_list = []\n",
    "\n",
    "            if not token:\n",
    "                return feature_list\n",
    "\n",
    "            # Capitalization\n",
    "            if token[0].isupper():\n",
    "                feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "            # Number\n",
    "            if re.search(self._pattern, token) is not None:\n",
    "                feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "            # Punctuation\n",
    "            punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "            if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "                feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "            # Suffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"SUF_\" + token[-1:])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"SUF_\" + token[-2:])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"SUF_\" + token[-3:])\n",
    "\n",
    "            # Current word\n",
    "            feature_list.append(\"WORD_\" + token)\n",
    "            \n",
    "            # Previous works\n",
    "            if idx != 0:\n",
    "                feature_list.append(\"PREV_\" + tokens[idx - 1])\n",
    "            # Next works\n",
    "            if idx != len(tokens) - 1:\n",
    "                feature_list.append(\"NEXT_\" + tokens[idx + 1])\n",
    "            ####\n",
    "\n",
    "            return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f78d5e2",
   "metadata": {},
   "source": [
    "Train your custom CRF tagger, then test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21985a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CustomCRF_NER_tagger(train_set):\n",
    "    CCRF = CustomCRFTagger()\n",
    "    CCRF.train(train_set, 'model.crf.tagger')\n",
    "    return CCRF\n",
    "\n",
    "tagger = train_CustomCRF_NER_tagger(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77c71c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Disease = 0.6868005932317649\n",
      "F1 score for class Chemical = 0.8361536123214104\n",
      "Macro-average f1 score = 0.7614771027765876\n"
     ]
    }
   ],
   "source": [
    "predicted_tags_val = tagger.tag_sents(val_sentences_ner)\n",
    "cal_span_level_f1(val_dataset, predicted_tags_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc6a4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8206273474774134\n",
      "F1 score for class Disease = 0.6917021551167892\n",
      "Macro-average f1 score = 0.7561647512971013\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = tagger.tag_sents(test_sentences_ner)\n",
    "cal_span_level_f1(test_dataset, predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf66467",
   "metadata": {},
   "source": [
    "POS tags can be used as features for tasks like NER. The code below defining another custom CRF tagger that also include POS tags as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c86e7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFTaggerWithPOS(CustomCRFTagger):\n",
    "    _current_tokens = None\n",
    "    \n",
    "    def _get_features(self, tokens, index):\n",
    "        \"\"\"\n",
    "        Extract the features for a token and append the POS tag as an additional feature.\n",
    "        \"\"\"\n",
    "        basic_features = super()._get_features(tokens, index)\n",
    "        \n",
    "        # Get the pos tags for the current sentence and save it\n",
    "        if tokens != self._current_tokens:\n",
    "            self._pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "            self._current_tokens = tokens\n",
    "            \n",
    "        basic_features.append(self._pos_tagged_tokens[index][1])\n",
    "        \n",
    "        return basic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8779e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CRF_NER_tagger_with_POS(train_set):\n",
    "    tagger = CRFTaggerWithPOS()\n",
    "    tagger.train(train_set, 'model.crf.tagger')\n",
    "    return tagger\n",
    "\n",
    "tagger = train_CRF_NER_tagger_with_POS(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f6a24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Disease = 0.6861451460885957\n",
      "F1 score for class Chemical = 0.8416180317971423\n",
      "Macro-average f1 score = 0.763881588942869\n"
     ]
    }
   ],
   "source": [
    "predicted_tags_val = tagger.tag_sents(val_sentences_ner)\n",
    "cal_span_level_f1(val_dataset, predicted_tags_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c85fdc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class Chemical = 0.8257102558936128\n",
      "F1 score for class Disease = 0.6874678993323061\n",
      "Macro-average f1 score = 0.7565890776129595\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = tagger.tag_sents(test_sentences_ner)\n",
    "cal_span_level_f1(test_dataset, predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c6357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
